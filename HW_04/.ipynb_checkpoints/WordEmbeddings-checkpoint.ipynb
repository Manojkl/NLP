{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d757077c2e9b853138564450eb0dd923",
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <h1>Natural Language Processing</h1>\n",
    "    <h3>General Information:</h3>\n",
    "    <p>Please do not add or delete any cells. Answers belong into the corresponding cells (below the question). If a function is given (either as a signature or a full function), you should not change the name, arguments or return value of the function.<br><br> If you encounter empty cells underneath the answer that can not be edited, please ignore them, they are for testing purposes.<br><br>When editing an assignment there can be the case that there are variables in the kernel. To make sure your assignment works, please restart the kernel and run all cells before submitting (e.g. via <i>Kernel -> Restart & Run All</i>).</p>\n",
    "    <p>Code cells where you are supposed to give your answer often include the line  ```raise NotImplementedError```. This makes it easier to automatically grade answers. If you edit the cell please outcomment or delete this line.</p>\n",
    "    <h3>Submission:</h3>\n",
    "    <p>Please submit your notebook via the web interface (in the main view -> Assignments -> Submit). The assignments are due on <b>Wednesday at 15:00</b>. If this does not work there is a submission slot on LEA.</p>\n",
    "    <h3>Group Work:</h3>\n",
    "    <p>You are allowed to work in groups of up to three people. Please enter the UID (your username here) of each member of the group into the next cell. We apply plagiarism checking, so do not submit solutions from other people except your team members. If an assignment has a copied solution, the task will be graded with 0 points for all people with the same solution.</p>\n",
    "    <h3>Questions about the Assignment:</h3>\n",
    "    <p>If you have questions about the assignment please post them in the LEA forum before the deadline. Don't wait until the last day to post questions.</p>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Group Work:\n",
    "Enter the UID (LEA username) of each team member into the variables. \n",
    "If you work alone please fill the first variable only.\n",
    "'''\n",
    "member1 = 'mkolpe2s'\n",
    "member2 = 'agomez2s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-2-de8ee08251c9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-de8ee08251c9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install gensim\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install gensim\n",
    "import tens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "61e3aa3e34f19aa9c4c624afafe52b2f",
     "grade": false,
     "grade_id": "intro_1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# What you need\n",
    "\n",
    "For this assignment we will use ```SpaCy```. This module helps us in processing text and has many features.\n",
    "We want to use it for tokenizing text. For this you need a language model. If the language model is not installed please execute ```!python -m spacy download en``` in a cell. Then reload ```spacy``` and try loading the model with ```spacy.load('en_core_web_sm')```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1b7227fa5c7b13d0a39bb721105a4217",
     "grade": false,
     "grade_id": "intro_2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Word Embeddings\n",
    "\n",
    "For training word embeddings we will use the ```gensim``` package.\n",
    "\n",
    "We can choose ```Word2Vec``` or ```FastText``` from ```gensim.models```.\n",
    "\n",
    "To train a model you give a corpus as a list of sentences which are in turn lists of tokens.\n",
    "\n",
    "*Example:*\n",
    "\n",
    "```\n",
    "sentences = gutenberg.sents('austen-emma.txt')\n",
    "model = Word2Vec(sentences, size=100, window=5, min_count=1)\n",
    "```\n",
    "This will train a model with vectors of ```size=100```, using a context window (n-gram) of size ```window=5``` and taking into account words that appear at least ```min_count=1``` times in our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ce6b6e4fbdf246c7742992713fb1fa7d",
     "grade": false,
     "grade_id": "intro_3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Extracting Information from Wikipedia\n",
    "\n",
    "A great source for structured text is Wikipedia. To access the content of it via Python I wrote a little helper class on top of the wikipedia-api package.\n",
    "\n",
    "It has two methods, one gives you the name of all pages under a category (up to a depth of ```max_level```).\n",
    "\n",
    "The other method gives you the tokenized content of a page you specify by name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0f3df4e69f0048c1ffd46f7cbafc557",
     "grade": false,
     "grade_id": "wikiextractor",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "import spacy\n",
    "\n",
    "class WikiExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.wiki = wikipediaapi.Wikipedia(language='en')\n",
    "        self.nlp = spacy.load('en_core_web_sm', disable=['tagger', 'ner', 'parser'])\n",
    "        self.nlp.add_pipe(self.nlp.create_pipe('sentencizer'))\n",
    "        \n",
    "    def pages_in_category(self, category, level=0, max_level=1):\n",
    "        if type(category) == str:\n",
    "            if not category.startswith('Category:'):\n",
    "                category = 'Category:' + category\n",
    "            category = self.wiki.page(category)\n",
    "        pages = []\n",
    "        if level >= max_level:\n",
    "            return pages\n",
    "        for c in category.categorymembers.values():\n",
    "            if c.ns == wikipediaapi.Namespace.CATEGORY:\n",
    "                pages.extend(self.pages_in_category(c, level + 1, max_level))\n",
    "            else:\n",
    "                pages.append(c.title)\n",
    "        return pages\n",
    "    \n",
    "    def extract_from_page_name(self, page_name):\n",
    "        doc = self.nlp(self.wiki.page(page_name).text)\n",
    "        parsed = []\n",
    "        for sent in doc.sents:\n",
    "            parsed.append([str(t) for t in sent])\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b80b43c74f16de6323af644fe618f567",
     "grade": false,
     "grade_id": "corpusA_corpusB_corpusC_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1. Create a Corpus [15 Points]\n",
    "\n",
    "We want to create a corpus from the Wikipedia category ```Natural Language Processing```. For this we want all pages in this category and all sub-categories up to a depth of 3 (this should be 794 pages).\n",
    "\n",
    "### 1.1 Save the names of the pages in a variable called ```pages```. Use the WikiExtractor to get the page names. [5 Points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab8fc22cb4318093e433a643654e8f81",
     "grade": false,
     "grade_id": "corpusA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 3 pages from the category are:\n",
      " ['Natural language processing', 'Outline of natural language processing', 'Abdul Majid Bhurgri Institute of Language Engineering']\n",
      "The last  3 pages from the category are:\n",
      " ['Word sense', 'Word-sense induction', 'Yarowsky algorithm']\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "wikiApi = WikiExtractor()\n",
    "pages = wikiApi.pages_in_category('Natural language processing', level=0, max_level=3)\n",
    "\n",
    "print('The first 3 pages from the category are:\\n {}'.format(pages[:3]))\n",
    "print('The last  3 pages from the category are:\\n {}'.format(pages[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "724c9986f166aba6070fbcd1f9baeed2",
     "grade": true,
     "grade_id": "test_corpusA",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "38d1cc4181d054f8a423a9be62539db8",
     "grade": false,
     "grade_id": "corpusB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.2 Tokenize the pages using the WikiExtractor [7 Points]\n",
    "\n",
    "Save the tokenized pages in a variable called ```corpus```. This should contain a list of sentences (which are lists of tokens) for all the articles from the category. This might take a few minutes depending on the response time of Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "22eedee3802db97918703c0348627712",
     "grade": true,
     "grade_id": "corpusB",
     "locked": false,
     "points": 7,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first sentence in our corpus is:\n",
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'linguistics', ',', 'computer', 'science', ',', 'information', 'engineering', ',', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', '(', 'natural', ')', 'languages', ',', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to', 'process', 'and', 'analyze', 'large', 'amounts', 'of', 'natural', 'language', 'data', '.']\n",
      "The last  sentence in our corpus is:\n",
      "['189â€“196', ',', '1995', '.']\n",
      "CPU times: user 20.8 s, sys: 385 ms, total: 21.2 s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "for curr_page in pages:\n",
    "    curr_corpus = wikiApi.extract_from_page_name(curr_page)\n",
    "    for sentences in curr_corpus:\n",
    "        corpus.append(sentences)\n",
    "    \n",
    "print('The first sentence in our corpus is:\\n{}'.format(corpus[0]))\n",
    "print('The last  sentence in our corpus is:\\n{}'.format(corpus[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e358c0a915cb6fa097a4d16114db132a",
     "grade": false,
     "grade_id": "corpusC_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1.3 Save your corpus [3 Points]\n",
    "\n",
    "Since we don't want to extract the corpus again everytime we run this notebook, we would like to save our corpus to a file. For this we can use the built-in Python module ```pickle```. Save your file as ```corpus.pkl```.\n",
    "\n",
    "*Example:*\n",
    "\n",
    "Saving data:\n",
    "\n",
    "```\n",
    "import pickle\n",
    "\n",
    "some_data = [...]\n",
    "with open('my_file.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(some_data)\n",
    "```\n",
    "\n",
    "Loading data:\n",
    "\n",
    "```\n",
    "import pickle\n",
    "\n",
    "with open('my_file.pkl', 'rb') as f:\n",
    "    some_data = pickle.loads(f.read())\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a6bdf43a55f846f5be520055a02ca728",
     "grade": false,
     "grade_id": "corpusC",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "# YOUR CODE HERE\n",
    "with open('corpus.pkl', 'wb') as f:\n",
    "    f.write(pickle.dumps(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fdcf29f6d99e7e0835e455ab3bd1ea27",
     "grade": true,
     "grade_id": "test_corpusC",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a53421b1c9f4289560d9d83e0e073e11",
     "grade": false,
     "grade_id": "create_modelA_create_modelB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Word2Vec [10 Points]\n",
    "### 2.1 Training a Word2Vec model [7 Points]\n",
    "\n",
    "In the first task you should train a model on your corpus. Load your corpus from the pickled file ```corpus.pkl```.\n",
    "\n",
    "Create a Word2Vec model with vectors of size 60, with a window size of 5 and a min count of 3.\n",
    "\n",
    "Store this in the variable ```model_w2v```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3fe3885ed02b87d62938fc6703d621d4",
     "grade": false,
     "grade_id": "create_modelA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import pickle\n",
    "\n",
    "model_w2v = None\n",
    "# YOUR CODE HERE\n",
    "with open('corpus.pkl', 'rb') as f:\n",
    "    corpus = pickle.loads(f.read())\n",
    "\n",
    "    \n",
    "model_w2v = Word2Vec(corpus, size=60, window=5, min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45072b7de80433f327125ade1af2b801",
     "grade": true,
     "grade_id": "test_create_modelA",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8e5f60d497be8f9076570719b4da7807",
     "grade": false,
     "grade_id": "create_modelB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 2.2 Saving your model [3 Points]\n",
    "\n",
    "To save and load a model we can use ```gensim```. We can just call ```model.save('mymodel.model')```.\n",
    "\n",
    "Save your model in the file ```model_w2v.model```.\n",
    "\n",
    "To load your file again you can ```Word2Vec.load('mymodel.model')```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ba99eb07a63ced936ffac4494d505ade",
     "grade": false,
     "grade_id": "create_modelB",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "model_w2v.save('model_w2v.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57d83902a8587550a2d2d856bdc3bc4e",
     "grade": true,
     "grade_id": "test_create_modelB",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c8a6d293433e2fa6cb9c1fdb67440516",
     "grade": false,
     "grade_id": "model_usingA_model_usingB_model_usingC_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3. Using the model [20 Points]\n",
    "\n",
    "### 3.1 Finding the most similar words to a given word [7 Points]\n",
    "\n",
    "We now want to find the most similar words to a given word.\n",
    "\n",
    "For this we need to access the KeyedVectors of the model via ```model.wv.most_similar('word')```.\n",
    "\n",
    "You are given the words ```['natural', 'language', 'processing', 'is', 'fun', 'ELIZA']```.\n",
    "\n",
    "For each word store the result in the list ```most_similar_words```.\n",
    "\n",
    "This should contain an entry for each input word as a tuple ```(input_word, most_similar_word, similarity)```.\n",
    "\n",
    "An example for an entry would be ```('POS', 'tagging', 0.9154)```. This means the most similar word to ```POS``` is ```tagging``` with a similarity of ```0.9154```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bddcdbce2821e05d87e2563c6e05fd48",
     "grade": false,
     "grade_id": "model_usingA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar word to \"natural\" is \"processing\" with a similarity of 0.8692\n",
      "The most similar word to \"language\" is \"processing\" with a similarity of 0.7313\n",
      "The most similar word to \"processing\" is \"understanding\" with a similarity of 0.8926\n",
      "The most similar word to \"is\" is \"crude\" with a similarity of 0.7103\n",
      "The most similar word to \"interesting\" is \"KWIC\" with a similarity of 0.9240\n",
      "The most similar word to \"ELIZA\" is \"reCAPTCHA\" with a similarity of 0.9395\n",
      "The most similar word to \"POS\" is \"tagger\" with a similarity of 0.9254\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "input_words = ['natural', 'language', 'processing', 'is', 'interesting', 'ELIZA', 'POS']\n",
    "most_similar_words = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "model_w2v = Word2Vec.load('model_w2v.model')\n",
    "\n",
    "for word in input_words:\n",
    "    if( word in model_w2v.wv.vocab ):\n",
    "        result = model_w2v.wv.most_similar(word, topn=1)[0]\n",
    "        \n",
    "        entry = [word]\n",
    "        entry.append(result[0])\n",
    "        entry.append(result[1])\n",
    "        \n",
    "        most_similar_words.append(tuple(entry))\n",
    "        \n",
    "    \n",
    "for entry in most_similar_words:\n",
    "    print('The most similar word to \"{}\" is \"{}\" with a similarity of {:.4f}'.format(*entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "332b7b642d94342364ccbc0b887f0f2c",
     "grade": true,
     "grade_id": "test_model_usingA",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "89f592a4e2bf463e489d04d35a62832b",
     "grade": false,
     "grade_id": "model_usingB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.2 Finding out the most similar word to a list of given words [7 Points]\n",
    "\n",
    "Instead of just finding the most similar word to a single word, we can also find the most similar word to a bunch of words at the same time.\n",
    "\n",
    "This can be done by calling ```most_similar(positive=[word1, word2, ...])```.\n",
    "\n",
    "Do this for the following input: \n",
    "```\n",
    "[('natural', 'language'), \n",
    " ('natural', 'understanding'), \n",
    " ('sentence', 'tokenization'),\n",
    " ('chatbot', 'ELIZA'),\n",
    " ('dependency', 'parsing'),\n",
    " ('POS', 'tagging'),\n",
    " ('probability', 'theory')]\n",
    "```\n",
    "\n",
    "This means for the first one you need to find the most similar word to ```('natural', 'language')```.\n",
    "\n",
    "Store your result in the list ```most_similar_positive_word```, again in the same format as for the previous task. \n",
    "\n",
    "\n",
    "Each entry should look like this:\n",
    "\n",
    "```(('probability', 'theory'), 'concept', 0.8886)``` saying the most similar word to ```('probability', 'theory')``` is ```concept```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6259528005b4e7be9517cb7454b2c237",
     "grade": false,
     "grade_id": "model_usingB",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most similar word to the words ('natural', 'language') is \"processing\" with a similarity of 0.8933\n",
      "The most similar word to the words ('natural', 'understanding') is \"processing\" with a similarity of 0.9184\n",
      "The most similar word to the words ('sentence', 'tokenization') is \"lemma\" with a similarity of 0.9223\n",
      "The most similar word to the words ('chatbot', 'ELIZA') is \"progress\" with a similarity of 0.9224\n",
      "The most similar word to the words ('dependency', 'parsing') is \"traditional\" with a similarity of 0.9315\n",
      "The most similar word to the words ('POS', 'tagging') is \"tagger\" with a similarity of 0.9015\n",
      "The most similar word to the words ('probability', 'theory') is \"choice\" with a similarity of 0.8837\n"
     ]
    }
   ],
   "source": [
    "input_words = [\n",
    "    ('natural', 'language'), \n",
    "    ('natural', 'understanding'), \n",
    "    ('sentence', 'tokenization'),\n",
    "    ('chatbot', 'ELIZA'),\n",
    "    ('dependency', 'parsing'),\n",
    "    ('POS', 'tagging'),\n",
    "    ('probability', 'theory')]\n",
    "most_similar_positive_word = []\n",
    "\n",
    "# YOUR CODE HERE\n",
    "for word_list in input_words:\n",
    "    flag = True\n",
    "    for word in word_list:\n",
    "        if(word not in model_w2v.wv.vocab):\n",
    "            flag = False\n",
    "            break\n",
    "    if(flag):\n",
    "        result = model_w2v.wv.most_similar(positive=word_list, topn=1)[0]\n",
    "        \n",
    "        entry = [word_list]\n",
    "        entry.append(result[0])\n",
    "        entry.append(result[1])\n",
    "        \n",
    "        most_similar_positive_word.append(entry)\n",
    "\n",
    "for entry in most_similar_positive_word:\n",
    "    print('The most similar word to the words {} is \"{}\" with a similarity of {:.4f}'.format(*entry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7ab70c82778f2dbbc432cb82cbf6c04f",
     "grade": true,
     "grade_id": "test_model_usingB",
     "locked": true,
     "points": 7,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c39922c9301a0c2208daf98ddc402e65",
     "grade": false,
     "grade_id": "model_usingC_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.3 Finding out what does not match [6 Points]\n",
    "\n",
    "We can provide our model with a list of tokens (words) and find out which one does not match using ```my_model.wv.doesnt_match([word1, word2, ...])```\n",
    "\n",
    "You are given the following list, where each sublist refers to a set of words where we want to find out what does not match.\n",
    "\n",
    "```\n",
    "input_words = [['sentiment', 'gram', 'bigram', 'trigram'],\n",
    "               ['named', 'entity', 'detection', 'recognition'], \n",
    "               ['verb', 'noun', 'phrase', 'extraction'],\n",
    "               ['dependency', 'tagging', 'POS', 'speech'],\n",
    "               ['stemming', 'tagging', 'lemmatizing', 'trigram']]\n",
    "```\n",
    "\n",
    "For each sublist, create an entry in the list ```does_not_match``` that holds the word that does not match. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "070992720939598fc03d9c1bca709b4c",
     "grade": false,
     "grade_id": "model_usingC",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the list ['sentiment', 'gram', 'bigram', 'trigram'], the word \"sentiment\" does not match!\n",
      "From the list ['named', 'entity', 'detection', 'recognition'], the word \"detection\" does not match!\n",
      "From the list ['verb', 'noun', 'phrase', 'extraction'], the word \"extraction\" does not match!\n",
      "From the list ['dependency', 'tagging', 'POS', 'speech'], the word \"dependency\" does not match!\n",
      "From the list ['stemming', 'tagging', 'lemmatizing', 'trigram'], the word \"trigram\" does not match!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/anaconda3/lib/python3.7/site-packages/gensim/models/keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    }
   ],
   "source": [
    "input_words = [['sentiment', 'gram', 'bigram', 'trigram'],\n",
    "               ['named', 'entity', 'detection', 'recognition'], \n",
    "               ['verb', 'noun', 'phrase', 'extraction'],\n",
    "               ['dependency', 'tagging', 'POS', 'speech'],\n",
    "               ['stemming', 'tagging', 'lemmatizing', 'trigram']]\n",
    "\n",
    "does_not_match = []\n",
    "# YOUR CODE HERE\n",
    "for word_list in input_words:\n",
    "    wrong_word = model_w2v.wv.doesnt_match(word_list)\n",
    "    does_not_match.append(wrong_word)\n",
    "\n",
    "for odd_one, sublist in zip(does_not_match, input_words):\n",
    "    print('From the list {}, the word \"{}\" does not match!'.format(sublist, odd_one))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acab41e7facdb3c9979ac31c21672c1d",
     "grade": true,
     "grade_id": "test_model_usingC",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9a5f22e3ea433868997e794089e3898e",
     "grade": false,
     "grade_id": "similarityA_similarityB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4. Similarity between documents [19 Points]\n",
    "\n",
    "Word2Vec tells us how similar words are. But often we are interested in how similar documents or sentences are.\n",
    "\n",
    "### 4.1 SOWE [11 Points]\n",
    "\n",
    "There is a naive way of doing this by summing up the vectors of each document and calculating the cosine similarity between those. This is called sum of word embeddings (SOWE).\n",
    "\n",
    "The vector of a word can be accessed via ```model.wv[word]```.\n",
    "\n",
    "Complete the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "865964f5fdd156005c4084a8a739ca35",
     "grade": false,
     "grade_id": "similarityA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/manoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7672827839851379"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "def SOWE(model: Word2Vec, doc1: [str], doc2: [str]) -> float:\n",
    "    '''\n",
    "    Calculate the SOWE similarity between two documents\n",
    "    \n",
    "    Arguments:\n",
    "        model -- a word embedding model\n",
    "        doc1  -- the first document as a list of tokens ['This', 'is', 'a', 'document']\n",
    "        doc2  -- the second document as a list of tokens ['This', 'is', 'a', 'document']\n",
    "    Returns:\n",
    "        sim   -- the cosine similarity between the two documents\n",
    "    '''\n",
    "    m = 0\n",
    "    for i in doc1:\n",
    "        m+=model[i]\n",
    "    n = 0\n",
    "    for i in doc2:\n",
    "        n+=model[i]\n",
    "    result = 1 - spatial.distance.cosine(m, n)\n",
    "    return result\n",
    "\n",
    "SOWE(model_w2v, ['part', 'of', 'speech', 'tagging', 'is', 'interesting'], \n",
    "                ['dependency', 'parsing', 'is', 'interesting', 'too'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "24534ea35040fc6a608c00e9c2c57c35",
     "grade": true,
     "grade_id": "test_similarityA",
     "locked": true,
     "points": 11,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "07ecfb276d15017587855bdf3fafbb3b",
     "grade": false,
     "grade_id": "similarityB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 4.2 Finding the most similar document [8 Points]\n",
    "\n",
    "You are given a list of documents ```docs```. And a document ```target_doc```.\n",
    "\n",
    "Create a list ```similarity``` that holds an entry for each document and the similarity to the target document.\n",
    "\n",
    "Sort this list by the similarity in descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa3108ff392c4e64a610780c50101427",
     "grade": false,
     "grade_id": "similarityB",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"people say POS tagging is useful\" is 0.75 similar to the target.\n",
      "The sentence \"some claim dependency parsing is fun\" is 0.71 similar to the target.\n",
      "The sentence \"sentiment analysis is not easy\" is 0.66 similar to the target.\n",
      "The sentence \"ELIZA was a chatbot\" is 0.44 similar to the target.\n",
      "The sentence \"trigrams are similar to bigrams\" is 0.49 similar to the target.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "/home/manoj/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "docs = [\n",
    "    ['people', 'say', 'POS', 'tagging', 'is', 'useful'],\n",
    "    ['some', 'claim', 'dependency', 'parsing', 'is', 'fun'],\n",
    "    ['sentiment', 'analysis', 'is', 'not', 'easy'], \n",
    "    ['ELIZA', 'was', 'a', 'chatbot'],\n",
    "    ['trigrams', 'are', 'similar', 'to', 'bigrams']\n",
    "]\n",
    "\n",
    "target_doc = ['Natural', 'language', 'understanding', 'is', 'hard']\n",
    "similarity = []\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i in docs:\n",
    "    k = []\n",
    "    k.append(i)\n",
    "    k.append(SOWE(model_w2v,i, target_doc)) \n",
    "    similarity.append(k)\n",
    "    \n",
    "for entry in similarity:\n",
    "    print('The sentence \"{}\" is {:.2f} similar to the target.'.format(\n",
    "        ' '.join(entry[0]),\n",
    "        entry[1]\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "34b39f876e086b6dabbcb9f41596ec78",
     "grade": true,
     "grade_id": "test_similarityB",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12f18449149499c9638b63cfc352111c",
     "grade": false,
     "grade_id": "insightsA_insightsB_insightsC_insightsD_insightsE_insightsF_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 5. Insights on how to choose training parameters [36 Points]\n",
    "\n",
    "When training a model it is important to choose a good vector size. If they are too small you will not encode enough information, if they are too big you waste memory.\n",
    "\n",
    "One way to get an estimate for how to choose the size is to start with a certain size and then apply PCA (principal component analysis) to the vectors. PCA is used for dimensionality reduction. You can give it vectors of a certain size and map them to smaller vectors. PCA gives us the mapping between the high and the low dimensional vectors. PCA also tells us how much variance of the original data is encoded in each component.\n",
    "\n",
    "We will use the implementation from [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8d1a85b1c2018cf7a4b996bf0f509ebf",
     "grade": false,
     "grade_id": "insightsA_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.1.1 Finding out how much variance is encoded in each dimension [6 Points]\n",
    "\n",
    "To access all the vectors from your word embedding model, you can call ```model_w2v.wv.vectors```.\n",
    "\n",
    "Perform PCA on this with ```n_components=60```. Store the explained variance ratio in the variable ```variance```.\n",
    "\n",
    "*Hint: If you have trouble doing this, look at the examples in the scikit-learn docs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ef82b487f7c3800aa482a195f6b61b0",
     "grade": false,
     "grade_id": "insightsA",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the information about the first 3 components.\n",
      "Component number 1 encodes 0.24 percent of the variance.\n",
      "Component number 2 encodes 0.21 percent of the variance.\n",
      "Component number 3 encodes 0.14 percent of the variance.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "variance = []\n",
    "\n",
    "vectors = model_w2v.wv.vectors\n",
    "pca = PCA(n_components=60)\n",
    "pca.fit(vectors)\n",
    "variance = pca.explained_variance_ratio_\n",
    "# print(variance)\n",
    "print('Printing the information about the first 3 components.')\n",
    "for i in range(3):\n",
    "    print('Component number {} encodes {:.2f} percent of the variance.'.format(i + 1, variance[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "adc557ebf05a5b864d60e41690586de3",
     "grade": true,
     "grade_id": "test_insightsA",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fda814c0e859d8e8e724f639f898bc75",
     "grade": false,
     "grade_id": "insightsB_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.1.2 Visualization [6 Points]\n",
    "\n",
    "Create a bar chart from the variance. The x-axis denotes the number of the component (starting at 0) and the y-axis the amount of variance encoded.\n",
    "\n",
    "As always, make sure your plot has labels, a legend, a title and a grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ebb6fdaeebe5338cc17e0d4a5db28373",
     "grade": true,
     "grade_id": "insightsB",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# YOUR CODE HERE\n",
    "x = np.arange(0,60)\n",
    "\n",
    "plt.bar(x,variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bdf2e6dce15361e730bfe55ef1dda19c",
     "grade": false,
     "grade_id": "insightsC_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.1.3 Visualization of accumulated variance [6 Points]\n",
    "\n",
    "Now we want to find out how many components we actually need to encode 99% of the variance of the original data.\n",
    "\n",
    "For this we will first create a plot of the accumulated variance. Store this variance in the variable ```accumulated_variance```. The first entry should tell us how much variance the first component stores, the second entry should tell us the variance of the first and second compononent summed together and so on.\n",
    "\n",
    "Plot this as a bar chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "43c1ac567d9891d7574fb74413846d1c",
     "grade": true,
     "grade_id": "insightsC",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOkElEQVR4nO3df6zdd13H8eeLloHya2CLWdaWO2JBGgIbuRmQGR2/TAem/WcxW8SgmfQfqhiIpgtm6vxnQhQxmWgDCBLdHFOx2aqVjBGNcaN3MnBdrZRR7U3RFhiYSGRU3v5xviOnl9t7vrc77bnfT5+P5OSez+f76bnvT3ru6376Od/vt6kqJEnD97RZFyBJmg4DXZIaYaBLUiMMdElqhIEuSY1YP6tvvGHDhpqbm5vVt5ekQXrooYe+WlUblzs2s0Cfm5tjYWFhVt9ekgYpyb+f7ZhbLpLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakREwM9yUeSnEzyyFmOJ8nvJzma5AtJXjX9MiVJk/RZoX8U2L7C8euArd1jF/DBp16WJGm1JgZ6Vf098PUVhuwE/qRGHgAuTXLZtAqUJPUzjStFLweOj7UXu76vLB2YZBejVTxbtmyZwreWLg5ze+49o33strcMsq+lufTpW2ns+TCNQM8yfcv+N0hVtRfYCzA/P+9/laQmDeWHX+2ZRqAvApvH2puAE1N4XWlmnuoqVJqFaQT6PmB3kjuBVwPfrKrv226R1gJDWS2bGOhJ7gCuBTYkWQR+HXg6QFX9IbAfeDNwFPgW8PPnq1jpbAxqqUegV9WNE44X8I6pVSR13GOWVmdm90OXxhnS0lNnoOuCM7yl88NA13lleEsXjoGuqTG8pdky0HVODG9p7fH2uZLUCFfomsjVuDQMBrrOYHhLw+WWiyQ1whX6RczVuNQWA/0iYXhL7XPLRZIa4Qq9Qa7GpYuTK3RJaoSBLkmNcMtlwM52v3BJFydX6JLUCFfoA+EHnZImcYUuSY0w0CWpEW65rEFur0g6F67QJakRBrokNcJAl6RGuIc+Y+6XS5oWV+iS1AgDXZIaYaBLUiPcQ7+A3C+XdD65QpekRhjoktQIA12SGtFrDz3JduADwDrgQ1V125LjW4CPAZd2Y/ZU1f4p1zoo7pdLutAmrtCTrANuB64DtgE3Jtm2ZNivAXdV1VXADcAfTLtQSdLK+my5XA0crarHquoJ4E5g55IxBTy3e/484MT0SpQk9dEn0C8Hjo+1F7u+cb8BvDXJIrAf+MXlXijJriQLSRZOnTp1DuVKks6mzx56lumrJe0bgY9W1e8keS3w8SQvr6rvnvGHqvYCewHm5+eXvsZguV8uaS3os0JfBDaPtTfx/VsqNwF3AVTVPwHPBDZMo0BJUj99Av0gsDXJFUkuYfSh574lY/4DeANAkpcxCnT3VCTpApoY6FV1GtgNHAAOMzqb5VCSW5Ps6Ia9G3h7ks8DdwA/V1XNbKlI0hD0Og+9O6d8/5K+W8aePwpcM93SJEmr4ZWiktQI77a4Sp7RImmtcoUuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGuFpiyvwFEVJQ+IKXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRngeesdzziUNnSt0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMuyguLvIhIUotcoUtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RG9Ar0JNuTHElyNMmes4z56SSPJjmU5M+mW6YkaZKJ56EnWQfcDrwJWAQOJtlXVY+OjdkK3AxcU1WPJ3nh+SpYkrS8Piv0q4GjVfVYVT0B3AnsXDLm7cDtVfU4QFWdnG6ZkqRJ+gT65cDxsfZi1zfuJcBLkvxjkgeSbJ9WgZKkfvpc+p9l+mqZ19kKXAtsAv4hycur6htnvFCyC9gFsGXLllUXK0k6uz6BvghsHmtvAk4sM+aBqvoO8OUkRxgF/MHxQVW1F9gLMD8/v/SXwtQtvWcLeN8WSe3qs+VyENia5IoklwA3APuWjPkk8DqAJBsYbcE8Ns1CJUkrmxjoVXUa2A0cAA4Dd1XVoSS3JtnRDTsAfC3Jo8D9wK9U1dfOV9GSpO/X6/a5VbUf2L+k75ax5wW8q3tIkmbAK0UlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqRHrZ13AtMztufeM9rHb3jKjSiRpNlyhS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiF6BnmR7kiNJjibZs8K465NUkvnplShJ6mNioCdZB9wOXAdsA25Msm2Zcc8Bfgl4cNpFSpIm67NCvxo4WlWPVdUTwJ3AzmXG/RbwXuB/p1ifJKmnPoF+OXB8rL3Y9X1PkquAzVV1z0ovlGRXkoUkC6dOnVp1sZKks+sT6Fmmr753MHka8H7g3ZNeqKr2VtV8Vc1v3Lixf5WSpIn6BPoisHmsvQk4MdZ+DvBy4DNJjgGvAfb5wagkXVh9Av0gsDXJFUkuAW4A9j15sKq+WVUbqmququaAB4AdVbVwXiqWJC1rYqBX1WlgN3AAOAzcVVWHktyaZMf5LlCS1E+v+6FX1X5g/5K+W84y9tqnXpYkabW8UlSSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij1s+6gHMxt+feM9rHbnvLjCqRpLXDFbokNcJAl6RGGOiS1AgDXZIaYaBLUiN6BXqS7UmOJDmaZM8yx9+V5NEkX0hyX5IXTb9USdJKJgZ6knXA7cB1wDbgxiTblgz7HDBfVa8A7gbeO+1CJUkr67NCvxo4WlWPVdUTwJ3AzvEBVXV/VX2raz4AbJpumZKkSfoE+uXA8bH2Ytd3NjcBf7PcgSS7kiwkWTh16lT/KiVJE/UJ9CzTV8sOTN4KzAPvW+54Ve2tqvmqmt+4cWP/KiVJE/W59H8R2DzW3gScWDooyRuB9wA/UVXfnk55kqS++qzQDwJbk1yR5BLgBmDf+IAkVwF/BOyoqpPTL1OSNMnEQK+q08Bu4ABwGLirqg4luTXJjm7Y+4BnA59I8nCSfWd5OUnSedLrbotVtR/Yv6TvlrHnb5xyXZKkVfJKUUlqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJakSvQE+yPcmRJEeT7Fnm+DOS/Hl3/MEkc9MuVJK0somBnmQdcDtwHbANuDHJtiXDbgIer6ofAd4P/Pa0C5UkrazPCv1q4GhVPVZVTwB3AjuXjNkJfKx7fjfwhiSZXpmSpElSVSsPSK4HtlfVL3TtnwVeXVW7x8Y80o1Z7Npf6sZ8dclr7QJ2dc2XAkeeYv0bgK9OHDUMzmVtci5r08U8lxdV1cblDqzv8YeXW2kv/S3QZwxVtRfY2+N79pJkoarmp/V6s+Rc1ibnsjY5l+X12XJZBDaPtTcBJ842Jsl64HnA16dRoCSpnz6BfhDYmuSKJJcANwD7lozZB7yte3498OmatJcjSZqqiVsuVXU6yW7gALAO+EhVHUpyK7BQVfuADwMfT3KU0cr8hvNZ9Jipbd+sAc5lbXIua5NzWcbED0UlScPglaKS1AgDXZIaMdhAn3Q7grUsyUeSnOzO33+y7wVJPpXki93X58+yxr6SbE5yf5LDSQ4leWfXP7j5JHlmks8m+Xw3l9/s+q/obmnxxe4WF5fMutY+kqxL8rkk93Ttoc7jWJJ/SfJwkoWub3DvL4Aklya5O8m/dj8zr53mXAYZ6D1vR7CWfRTYvqRvD3BfVW0F7uvaQ3AaeHdVvQx4DfCO7u9iiPP5NvD6qnolcCWwPclrGN3K4v3dXB5ndKuLIXgncHisPdR5ALyuqq4cO197iO8vgA8Af1tVPwq8ktHfz/TmUlWDewCvBQ6MtW8Gbp51XaucwxzwyFj7CHBZ9/wy4MisazzHef018Kahzwf4QeCfgVczuopvfdd/xntvrT4YXS9yH/B64B5GF/8Nbh5drceADUv6Bvf+Ap4LfJnuZJTzMZdBrtCBy4HjY+3Frm/IfriqvgLQfX3hjOtZte4um1cBDzLQ+XTbFA8DJ4FPAV8CvlFVp7shQ3mv/R7wq8B3u/YPMcx5wOiq879L8lB3+xAY5vvrxcAp4I+7rbAPJXkWU5zLUAO9160GdOEkeTbwF8AvV9V/z7qec1VV/1dVVzJa4V4NvGy5YRe2qtVJ8lPAyap6aLx7maFreh5jrqmqVzHaYn1Hkh+fdUHnaD3wKuCDVXUV8D9MeatoqIHe53YEQ/NfSS4D6L6enHE9vSV5OqMw/9Oq+suue7DzAaiqbwCfYfS5wKXdLS1gGO+1a4AdSY4xujvq6xmt2Ic2DwCq6kT39STwV4x+0Q7x/bUILFbVg137bkYBP7W5DDXQ+9yOYGjGb5/wNkZ70Wted5vkDwOHq+p3xw4Nbj5JNia5tHv+A8AbGX1odT+jW1rAAOZSVTdX1aaqmmP0s/HpqvoZBjYPgCTPSvKcJ58DPwk8wgDfX1X1n8DxJC/tut4APMo05zLrDwqewgcMbwb+jdEe53tmXc8qa78D+ArwHUa/tW9itMd5H/DF7usLZl1nz7n8GKN/un8BeLh7vHmI8wFeAXyum8sjwC1d/4uBzwJHgU8Az5h1rauY07XAPUOdR1fz57vHoSd/1of4/urqvhJY6N5jnwSeP825eOm/JDViqFsukqQlDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiP8HxA+pVCcZbycAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "accumulated_variance = []\n",
    "\n",
    "m = 0\n",
    "for k in variance:\n",
    "    m+=k\n",
    "    accumulated_variance.append(m)\n",
    "plt.bar(x,accumulated_variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7b9782dbb93e6ef6447e4ed7ad6e776",
     "grade": false,
     "grade_id": "insightsD_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.1.4 Finding out a good estimate for the vector size for training our model [6 Points]\n",
    "\n",
    "Find out how many components are needed to encode ```99.9%``` of the variance of the original data.\n",
    "\n",
    "Store this in the variable ```n_components```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5eb1289dba21579eb235a11e6a598e1e",
     "grade": false,
     "grade_id": "insightsD",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need 47 components to encode 99% of the variance\n"
     ]
    }
   ],
   "source": [
    "n_components = 0\n",
    "# YOUR CODE HERE\n",
    "\n",
    "for i,j in enumerate(accumulated_variance):\n",
    "    if j>0.999:\n",
    "        n_components = i+1\n",
    "        break\n",
    "print('We need {} components to encode 99% of the variance'.format(n_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dabdd8a61693d681715dbe9070808e0a",
     "grade": true,
     "grade_id": "test_insightsD",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This is a test cell, please ignore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e1e8b39819b7d9b7ee48ce66b3a88b3c",
     "grade": false,
     "grade_id": "insightsE_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.2.1 Window size [6 Points]\n",
    "\n",
    "Please write down your understanding of how the window size affects the trained vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7a5c0e01d98225e9d1d4a3d93110edd3",
     "grade": true,
     "grade_id": "insightsE",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "* Larger windows tend to capture more topic/domain information.\n",
    "* Smaller windows tend to capture more about word itself.\n",
    "* Quality of the learned model depends on the material we are using for training, if the window size of 2 can capture the context of a word, but 5 is chosen, it will decrease the quality of the learnt model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0bed5a683775c2cc870cc141053eaa04",
     "grade": false,
     "grade_id": "insightsF_description",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 5.3.1 Min count [6 Points]\n",
    "\n",
    "Why would you want to exclude words that appear less than a certain number of times in the corpus?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2494e216d0340bbe63a184e823ebb6d",
     "grade": true,
     "grade_id": "insightsF",
     "locked": false,
     "points": 6,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "* To save memory.\n",
    "* Fast compuation of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "* https://stackoverflow.com/questions/18424228/cosine-similarity-between-2-number-lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
